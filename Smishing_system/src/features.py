# Smishing_system/src/features.py

import re
import pandas as pd
from iocextract import extract_urls
from collections import Counter

# ==============================================================================
# DICTIONARY - T·ª™ ƒêI·ªÇN T·ª™ KHO√Å
# ==============================================================================

# 1. T·ª´ kh√≥a t√†i ch√≠nh (Financial Keywords)
FINANCIAL_KEYWORDS = [
    'ti·ªÅn', 'ƒë·ªìng', 'tri·ªáu', 'ng√†n', 'chuy·ªÉn kho·∫£n', 'thanh to√°n', 'n·∫°p ti·ªÅn',
    'r√∫t ti·ªÅn', 's·ªë d∆∞', 't√†i kho·∫£n', 'stk', 'vcb', 'vietcombank', 'techcombank',
    'bidv', 'agribank', 'vpbank', 'acb', 'mb bank', 'ng√¢n h√†ng', 'bank',
    'credit', 'debit', 'visa', 'mastercard', 'the atm', 'th·∫ª t√≠n d·ª•ng',
    'vay', 'n·ª£', 'tr·∫£ g√≥p', 'l√£i su·∫•t', 'ph√≠', 'momo', 'zalopay', 'vnpay',
    'paytm', 'paypal', 'usdt', 'bitcoin'
]

# 2. T·ª´ kh√≥a kh·∫©n c·∫•p (Urgency Keywords)
URGENCY_KEYWORDS = [
    'g·∫•p', 'ngay', 'nhanh', 'kh·∫©n', 'l·∫≠p t·ª©c', 'h√¥m nay', 'tr∆∞·ªõc', 'h·∫øt h·∫°n',
    'expired', 'b·ªã kh√≥a', 'b·ªã ch·∫∑n', 'c·∫£nh b√°o', 'th√¥ng b√°o', 'warning',
    'canh bao', 'thong bao', 'gap', 'khan', 'truoc', 'het han'
]

# 3. T·ª´ kh√≥a h√†nh ƒë·ªông (Action Keywords - y√™u c·∫ßu user l√†m g√¨ ƒë√≥)
ACTION_KEYWORDS = [
    'truy c·∫≠p', 'click', 'nh·∫•n', 'b·∫•m', 'v√†o', 'k√≠ch', 'ƒëƒÉng nh·∫≠p', 'x√°c nh·∫≠n',
    'x√°c th·ª±c', 'c·∫≠p nh·∫≠t', 'n√¢ng c·∫•p', 'gia h·∫°n', 'k√≠ch ho·∫°t', 'li√™n h·ªá',
    'g·ªçi', 'nh·∫Øn', 'reply', 'tr·∫£ l·ªùi', 'download', 't·∫£i', 'c√†i ƒë·∫∑t',
    'ƒëƒÉng k√Ω', 'h·ªßy', 'nh·∫≠n', 'dang nhap', 'xac nhan', 'lien he', 'cap nhat'
]

# 4. T·ª´ kh√≥a th∆∞·ªüng/l·ª´a ƒë·∫£o (Reward/Scam Keywords)
REWARD_KEYWORDS = [
    'tr√∫ng', 'th∆∞·ªüng', 'may m·∫Øn', 'qu√†', 'khuy·∫øn m√£i', 'mi·ªÖn ph√≠', 'free',
    'gi·∫£m gi√°', 'gi√° shock', 'voucher', 'coupon', 'ho√†n ti·ªÅn', 'cashback',
    'trung', 'thuong', 'qua', 'mien phi', 'khuyen mai'
]

# 5. T·ª´ kh√≥a gi·∫£ m·∫°o c∆° quan (Impersonation Keywords)
IMPERSONATION_KEYWORDS = [
    'c√¥ng an', 'police', 'vi·ªán ki·ªÉm s√°t', 't√≤a √°n', 'court', 'b·ªô c√¥ng an',
    'b·ªô gtvt', 'b·ªô y t·∫ø', 'c·ª•c', 's·ªü', 'ph√≤ng', 'c∆° quan', 'ch√≠nh quy·ªÅn',
    'kho b·∫°c', 'thu·∫ø', 'h·∫£i quan', 'customs', 'c·∫£nh s√°t', 'vks', 
    'phcƒëgln', 'trung t√¢m', 'cong an', 'to an', 'co quan', 'canh sat'
]

# 6. Brandname ng√¢n h√†ng/d·ªãch v·ª• ch√≠nh th·ª©c
LEGITIMATE_BRANDS = [
    'viettel', 'mobifone', 'vinaphone', 'vietnamobile', 'gmobile',
    'vnpt', 'fpt', 'vccorp', 'being', 'shopee', 'lazada', 'tiki', 
    'grab', 'gojek', 'facebook', 'zalo', 'google'
]


# ==============================================================================
# C√ÅC H√ÄM TR√çCH XU·∫§T ƒê·∫∂C TR∆ØNG
# ==============================================================================

def extract_url_features(text):
    """
    Feature 1: ƒê·∫∑c tr∆∞ng li√™n quan ƒë·∫øn URL
    
    Returns:
        dict: {
            'has_url': 0/1,
            'num_urls': int,
            'has_suspicious_domain': 0/1,
            'url_length_avg': float
        }
    """
    urls = list(extract_urls(text))
    
    features = {
        'has_url': 1 if urls else 0,
        'num_urls': len(urls),
        'has_suspicious_domain': 0,
        'url_length_avg': 0.0
    }
    
    if urls:
        # ƒê·ªô d√†i trung b√¨nh c·ªßa URL
        features['url_length_avg'] = sum(len(url) for url in urls) / len(urls)
        
        # Ki·ªÉm tra domain ƒë√°ng ng·ªù
        suspicious_patterns = [
            r'\.xyz$', r'\.top$', r'\.club$', r'\.info$',  # TLD ƒë√°ng ng·ªù
            r'\d+\.com',  # Domain c√≥ nhi·ªÅu s·ªë: login123.com
            r'[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}',  # IP address
            r'(login|verify|update|secure|account|bank).*\.(com|vn|net)',  # T·ª´ ƒë√°ng ng·ªù trong domain
            r'[a-z]{20,}',  # Domain qu√° d√†i kh√¥ng ng·∫Øt
        ]
        
        for url in urls:
            url_lower = url.lower()
            for pattern in suspicious_patterns:
                if re.search(pattern, url_lower):
                    features['has_suspicious_domain'] = 1
                    break
            if features['has_suspicious_domain']:
                break
    
    return features


def extract_phone_features(text):
    """
    Feature 2: ƒê·∫∑c tr∆∞ng li√™n quan ƒë·∫øn s·ªë ƒëi·ªán tho·∫°i
    
    Returns:
        dict: {
            'has_phone': 0/1,
            'num_phones': int,
            'has_personal_phone': 0/1,  # SƒêT c√° nh√¢n (kh√¥ng ph·∫£i hotline/shortcode)
            'has_hotline': 0/1
        }
    """
    # Pattern b·∫Øt s·ªë ƒëi·ªán tho·∫°i Vi·ªát Nam
    phone_patterns = [
        r'\b(0|\+84|84)[3-9]\d{8}\b',  # SƒêT di ƒë·ªông VN: 0912345678, +84912345678
        r'\b1[8-9]00\d{4,6}\b',  # Hotline: 1800xxxx, 1900xxxx
        r'\b0[2]\d{8,9}\b',  # S·ªë c·ªë ƒë·ªãnh
    ]
    
    phones = []
    for pattern in phone_patterns:
        phones.extend(re.findall(pattern, text))
    
    # Lo·∫°i b·ªè c√°c s·ªë kh√¥ng ph·∫£i SƒêT (OTP, m√£ g√≥i, s·ªë ti·ªÅn)
    valid_phones = []
    for phone in phones:
        # Lo·∫°i b·ªè n·∫øu xung quanh c√≥ t·ª´ kh√≥a ch·ªâ s·ªë ti·ªÅn, m√£ OTP
        context_pattern = rf'.{{0,20}}{re.escape(phone)}.{{0,20}}'
        context = re.search(context_pattern, text)
        if context:
            context_text = context.group().lower()
            # Skip n·∫øu l√† m√£ OTP, s·ªë ti·ªÅn
            if not re.search(r'(otp|ma xac thuc|m√£ x√°c th·ª±c|\d+ƒë|\d+vnd|gb)', context_text):
                valid_phones.append(phone)
    
    features = {
        'has_phone': 1 if valid_phones else 0,
        'num_phones': len(valid_phones),
        'has_personal_phone': 0,
        'has_hotline': 0
    }
    
    # Ph√¢n lo·∫°i lo·∫°i s·ªë ƒëi·ªán tho·∫°i
    for phone in valid_phones:
        if re.match(r'1[8-9]00', phone):
            features['has_hotline'] = 1
        elif re.match(r'(0|\+84|84)[3-9]', phone):
            features['has_personal_phone'] = 1
    
    return features


def extract_text_features(text):
    """
    Feature 3: ƒê·∫∑c tr∆∞ng t·ª´ n·ªôi dung vƒÉn b·∫£n
    
    Returns:
        dict: {
            'message_length': int,
            'num_words': int,
            'num_digits': int,
            'digit_ratio': float,  # T·ª∑ l·ªá ch·ªØ s·ªë / t·ªïng k√Ω t·ª±
            'num_special_chars': int,
            'special_char_ratio': float,
            'num_uppercase': int,
            'uppercase_ratio': float,
            'has_mixed_language': 0/1  # L·∫´n ti·∫øng Vi·ªát kh√¥ng d·∫•u + c√≥ d·∫•u
        }
    """
    # Lo·∫°i b·ªè URL v√† SƒêT ƒë·ªÉ t√≠nh to√°n ch√≠nh x√°c h∆°n
    text_clean = re.sub(r'http[s]?://\S+|www\.\S+', '', text)
    text_clean = re.sub(r'\b(0|\+84|84)[3-9]\d{8}\b', '', text_clean)
    
    features = {
        'message_length': len(text),
        'num_words': len(text.split()),
        'num_digits': len(re.findall(r'\d', text)),
        'digit_ratio': 0.0,
        'num_special_chars': len(re.findall(r'[^a-zA-Z0-9\s√†√°·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠√®√©·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√¨√≠·ªâƒ©·ªã√≤√≥·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√π√∫·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±·ª≥√Ω·ª∑·ªπ·ªµƒë√Ä√Å√Ä·∫¢√É·∫†ƒÇ·∫Æ·∫∞·∫≤·∫¥·∫∂√Ç·∫§·∫¶·∫®·∫™·∫¨√à√â·∫∫·∫º·∫∏√ä·∫æ·ªÄ·ªÇ·ªÑ·ªÜ√å√ç·ªàƒ®·ªä√í√ì·ªé√ï·ªå√î·ªê·ªí·ªî·ªñ·ªò∆†·ªö·ªú·ªû·ª†·ª¢√ô√ö·ª¶≈®·ª§∆Ø·ª®·ª™·ª¨·ªÆ·ª∞·ª≤√ù·ª∂·ª∏·ª¥ƒê]', text)),
        'special_char_ratio': 0.0,
        'num_uppercase': len(re.findall(r'[A-Z]', text)),
        'uppercase_ratio': 0.0,
        'has_mixed_language': 0
    }
    
    if len(text) > 0:
        features['digit_ratio'] = features['num_digits'] / len(text)
        features['special_char_ratio'] = features['num_special_chars'] / len(text)
        features['uppercase_ratio'] = features['num_uppercase'] / len(text)
    
    # Ki·ªÉm tra mixed language (l·∫´n l·ªôn ti·∫øng Vi·ªát c√≥ d·∫•u v√† kh√¥ng d·∫•u)
    has_vietnamese_chars = bool(re.search(r'[√†√°·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠√®√©·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√¨√≠·ªâƒ©·ªã√≤√≥·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√π√∫·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±·ª≥√Ω·ª∑·ªπ·ªµƒë]', text.lower()))
    has_no_accent_vietnamese = bool(re.search(r'\b(ngan hang|tai khoan|chuyen khoan|thong bao|canh bao|xac nhan)\b', text.lower()))
    
    if has_vietnamese_chars and has_no_accent_vietnamese:
        features['has_mixed_language'] = 1
    
    return features


def extract_keyword_features(text):
    """
    Feature 4: ƒê·∫∑c tr∆∞ng t·ª´ c√°c t·ª´ kh√≥a ƒë·∫∑c bi·ªát
    
    Returns:
        dict: {
            'num_financial_keywords': int,
            'num_urgency_keywords': int,
            'num_action_keywords': int,
            'num_reward_keywords': int,
            'num_impersonation_keywords': int,
            'has_financial_keywords': 0/1,
            'has_urgency_keywords': 0/1,
            'has_action_keywords': 0/1,
            'has_reward_keywords': 0/1,
            'has_impersonation_keywords': 0/1,
            'keyword_density': float  # T·ªïng s·ªë keyword / s·ªë t·ª´
        }
    """
    text_lower = text.lower()
    
    # ƒê·∫øm s·ªë l∆∞·ª£ng keywords
    financial_count = sum(1 for kw in FINANCIAL_KEYWORDS if kw in text_lower)
    urgency_count = sum(1 for kw in URGENCY_KEYWORDS if kw in text_lower)
    action_count = sum(1 for kw in ACTION_KEYWORDS if kw in text_lower)
    reward_count = sum(1 for kw in REWARD_KEYWORDS if kw in text_lower)
    impersonation_count = sum(1 for kw in IMPERSONATION_KEYWORDS if kw in text_lower)
    
    total_keywords = financial_count + urgency_count + action_count + reward_count + impersonation_count
    num_words = len(text.split())
    
    features = {
        'num_financial_keywords': financial_count,
        'num_urgency_keywords': urgency_count,
        'num_action_keywords': action_count,
        'num_reward_keywords': reward_count,
        'num_impersonation_keywords': impersonation_count,
        'has_financial_keywords': 1 if financial_count > 0 else 0,
        'has_urgency_keywords': 1 if urgency_count > 0 else 0,
        'has_action_keywords': 1 if action_count > 0 else 0,
        'has_reward_keywords': 1 if reward_count > 0 else 0,
        'has_impersonation_keywords': 1 if impersonation_count > 0 else 0,
        'keyword_density': total_keywords / num_words if num_words > 0 else 0.0
    }
    
    return features


def extract_sender_features(sender_type):
    """
    Feature 5: ƒê·∫∑c tr∆∞ng t·ª´ lo·∫°i ng∆∞·ªùi g·ª≠i
    
    Args:
        sender_type: 'brandname', 'shortcode', 'personal_number', 'unknown'
    
    Returns:
        dict: {
            'is_brandname': 0/1,
            'is_shortcode': 0/1,
            'is_personal_number': 0/1,
            'is_unknown': 0/1
        }
    """
    sender_type_lower = str(sender_type).lower()
    
    features = {
        'is_brandname': 1 if sender_type_lower == 'brandname' else 0,
        'is_shortcode': 1 if sender_type_lower == 'shortcode' else 0,
        'is_personal_number': 1 if sender_type_lower == 'personal_number' else 0,
        'is_unknown': 1 if sender_type_lower == 'unknown' else 0
    }
    
    return features


# ==============================================================================
# H√ÄM T·ªîNG H·ª¢P - TR√çCH XU·∫§T T·∫§T C·∫¢ C√ÅC ƒê·∫∂C TR∆ØNG
# ==============================================================================

def extract_all_features(text, sender_type='unknown'):
    """
    Tr√≠ch xu·∫•t t·∫•t c·∫£ c√°c ƒë·∫∑c tr∆∞ng t·ª´ m·ªôt tin nh·∫Øn SMS
    
    Args:
        text (str): N·ªôi dung tin nh·∫Øn
        sender_type (str): Lo·∫°i ng∆∞·ªùi g·ª≠i
    
    Returns:
        dict: Dictionary ch·ª©a t·∫•t c·∫£ c√°c features
    """
    all_features = {}
    
    # 1. URL features
    all_features.update(extract_url_features(text))
    
    # 2. Phone features
    all_features.update(extract_phone_features(text))
    
    # 3. Text features
    all_features.update(extract_text_features(text))
    
    # 4. Keyword features
    all_features.update(extract_keyword_features(text))
    
    # 5. Sender features
    all_features.update(extract_sender_features(sender_type))
    
    return all_features


def extract_features_from_dataframe(df, content_col='content', sender_col='sender_type'):
    """
    Tr√≠ch xu·∫•t features cho to√†n b·ªô DataFrame
    
    Args:
        df (pd.DataFrame): DataFrame ch·ª©a d·ªØ li·ªáu SMS
        content_col (str): T√™n c·ªôt ch·ª©a n·ªôi dung tin nh·∫Øn
        sender_col (str): T√™n c·ªôt ch·ª©a lo·∫°i ng∆∞·ªùi g·ª≠i
    
    Returns:
        pd.DataFrame: DataFrame v·ªõi c√°c c·ªôt features m·ªõi
    """
    features_list = []
    
    for idx, row in df.iterrows():
        text = str(row[content_col])
        sender_type = row[sender_col] if sender_col in df.columns else 'unknown'
        
        features = extract_all_features(text, sender_type)
        features_list.append(features)
    
    # T·∫°o DataFrame t·ª´ list of dicts
    features_df = pd.DataFrame(features_list)
    
    # K·∫øt h·ª£p v·ªõi DataFrame g·ªëc
    result_df = pd.concat([df.reset_index(drop=True), features_df], axis=1)
    
    return result_df


# ==============================================================================
# H√ÄM CH·ªåN TOP FEATURES (theo paper - 5 features hi·ªáu qu·∫£ nh·∫•t)
# ==============================================================================

def get_top_5_features():
    """
    Tr·∫£ v·ªÅ danh s√°ch 5 features quan tr·ªçng nh·∫•t (d·ª±a tr√™n paper v√† kinh nghi·ªám)
    
    C√≥ th·ªÉ ƒëi·ªÅu ch·ªânh sau khi train model v√† feature importance analysis
    """
    return [
        'has_url',                      # Feature 1: C√≥ URL kh√¥ng?
        'has_phone',                    # Feature 2: C√≥ SƒêT kh√¥ng?
        'num_financial_keywords',       # Feature 3: S·ªë l∆∞·ª£ng t·ª´ kh√≥a t√†i ch√≠nh
        'num_urgency_keywords',         # Feature 4: S·ªë l∆∞·ª£ng t·ª´ kh√≥a kh·∫©n c·∫•p
        'is_personal_number',           # Feature 5: G·ª≠i t·ª´ SƒêT c√° nh√¢n?
    ]


def get_selected_features_df(df):
    """
    L·∫•y ch·ªâ 5 features quan tr·ªçng nh·∫•t t·ª´ DataFrame ƒë√£ extract
    
    Args:
        df (pd.DataFrame): DataFrame ƒë√£ c√≥ t·∫•t c·∫£ features
    
    Returns:
        pd.DataFrame: DataFrame ch·ªâ ch·ª©a 5 features ch√≠nh + label (n·∫øu c√≥)
    """
    top_features = get_top_5_features()
    
    # Gi·ªØ l·∫°i label n·∫øu c√≥
    cols_to_keep = top_features.copy()
    if 'label' in df.columns:
        cols_to_keep.insert(0, 'label')
    
    return df[cols_to_keep]


# ==============================================================================
# TEST & DEMO
# ==============================================================================

if __name__ == "__main__":
    # Test v·ªõi m·ªôt s·ªë m·∫´u SMS
    test_samples = [
        {
            'content': 'ACB: Tai khoan cua ban da mo dich vu tai chinh toan cau phi dich vu hang thang la 2.000.000VND se bi tru trong 2 gio .Neu khong phai ban mo dich vu vui long nhan vao https://acb-online-center.6app de huy',
            'sender_type': 'brandname',
            'expected': 'SMISHING'
        },
        {
            'content': 'Viettel thong bao: So tien tra truoc 12345 quy khach con 50.000d. Han su dung den 30/12/2025. Cam on.',
            'sender_type': 'shortcode',
            'expected': 'HAM'
        },
        {
            'content': 'Western Union TB: Vietcombank: 0071000986547. Tr·∫ßn Th·ªã Lan. Ref +19.56 USD. Nh·∫≠n 500.000 VND. Ngay 02/02/2025. Mgd: 1057425286. Nd: COC TIEN HANG. Qu√Ω kh√°ch nh·∫≠n ti·ªÅn VND v√†o website: https://sites.google.com/view/chuyennhantiennhanhquocte24h7',
            'sender_type': 'personal_number',
            'expected': 'SMISHING'
        }
    ]
    
    print("=" * 80)
    print("FEATURE EXTRACTION DEMO")
    print("=" * 80)
    
    for idx, sample in enumerate(test_samples, 1):
        print(f"\nüì© SAMPLE {idx} - Expected: {sample['expected']}")
        print(f"Content: {sample['content'][:100]}...")
        print(f"Sender: {sample['sender_type']}")
        print("-" * 80)
        
        features = extract_all_features(sample['content'], sample['sender_type'])
        
        # In ra c√°c features quan tr·ªçng
        print("üîç EXTRACTED FEATURES:")
        for key, value in features.items():
            if value > 0 or key in get_top_5_features():  # Ch·ªâ in features c√≥ gi√° tr·ªã ho·∫∑c thu·ªôc top 5
                print(f"  {key:30s}: {value}")
        
        print("-" * 80)
        print(f"‚úÖ TOP 5 FEATURES: {get_top_5_features()}")
        top_5_values = {k: features[k] for k in get_top_5_features()}
        print(f"   Values: {top_5_values}")
    
    print("\n" + "=" * 80)
    print("TEST COMPLETED")
    print("=" * 80)