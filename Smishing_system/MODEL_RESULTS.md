# ğŸ¤– Model Training Results - Smishing Detection

## ğŸ“Š Final Results Summary

**Training Date**: December 9, 2025  
**Dataset**: 2,603 SMS messages (Top 5 Features)  
**Target**: Detect Smishing SMS with 97.93% accuracy (paper benchmark)

---

## ğŸ† Best Model Performance

### **Random Forest Classifier** ğŸŒ²

| Metric | Score | Comment |
|--------|-------|---------|
| **Accuracy** | **93.09%** | âœ… Excellent |
| **Precision** | **86.21%** | High confidence in Smishing predictions |
| **Recall** | **43.86%** | âš ï¸ Missing 56% of Smishing cases |
| **F1-Score** | **58.14%** | Moderate balance |
| **AUC-ROC** | **0.8615** | Very good discrimination |
| **Training Time** | **0.20s** | Very fast |

---

## ğŸ“ˆ All Models Comparison

| Rank | Model | Accuracy | Precision | Recall | F1-Score | AUC-ROC | Time (s) |
|------|-------|----------|-----------|--------|----------|---------|----------|
| ğŸ¥‡ | **Random Forest** | **93.09%** | **86.21%** | 43.86% | 58.14% | 0.8615 | 0.20 |
| ğŸ¥ˆ | **SVM** | **93.09%** | **86.21%** | 43.86% | 58.14% | 0.7533 | 0.15 |
| ğŸ¥‰ | **Logistic Regression** | **93.09%** | **92.00%** | 40.35% | 56.10% | 0.8417 | 3.70 |
| 4ï¸âƒ£ | MLP (Backpropagation) | 88.68% | 48.28% | 49.12% | 48.70% | 0.7942 | 0.14 |

### ğŸ” Key Observations:

1. **Top 3 models cÃ³ cÃ¹ng Accuracy (93.09%)**
   - Random Forest, SVM, vÃ  Logistic Regression Ä‘á»u Ä‘áº¡t 93.09%
   - Random Forest Ä‘Æ°á»£c chá»n vÃ¬ AUC-ROC cao nháº¥t (0.8615)

2. **Precision cao (86-92%)**
   - Khi model dá»± Ä‘oÃ¡n Smishing â†’ cÃ³ 86-92% lÃ  Ä‘Ãºng
   - Ráº¥t Ã­t False Positives (tin nháº¯n Ham bá»‹ nháº§m lÃ  Smishing)

3. **Recall tháº¥p (~44%)**
   - Chá»‰ báº¯t Ä‘Æ°á»£c ~44% tin nháº¯n Smishing thá»±c sá»±
   - Khoáº£ng 56% Smishing bá»‹ bá» sÃ³t (False Negatives)

4. **MLP performance tháº¥p hÆ¡n**
   - CÃ³ thá»ƒ do dataset nhá» (2,603 samples)
   - Neural networks thÆ°á»ng cáº§n nhiá»u data hÆ¡n

---

## ğŸ¯ Comparison with Paper

| Source | Model | Accuracy | Gap |
|--------|-------|----------|-----|
| **Our Result** | Random Forest | **93.09%** | - |
| **DSmishSMS Paper** | Backpropagation | **97.93%** | **-4.84%** |

### ğŸ“‰ Reasons for Gap:

1. **Dataset Differences**
   - Paper: English SMS dataset
   - Ours: Vietnamese SMS dataset
   - Different linguistic patterns and scam tactics

2. **Imbalanced Data**
   - Ham: 2,319 (89.1%)
   - Smishing: 284 (10.9%)
   - Severe class imbalance â†’ Low recall

3. **Domain Checking Phase Missing**
   - Paper implements URL legitimacy checking
   - We only use content-based features
   - Missing ~5% accuracy boost

4. **Hyperparameter Tuning**
   - Our models use default parameters
   - Paper likely optimized hyperparameters

---

## ğŸ”‘ Feature Importance Analysis

### Random Forest Feature Importance:

| Rank | Feature | Importance | Insight |
|------|---------|------------|---------|
| 1ï¸âƒ£ | `is_personal_number` | **63.44%** | ğŸš¨ Smishing often from personal numbers |
| 2ï¸âƒ£ | `has_url` | **15.32%** | ğŸ”— URLs are strong Smishing indicators |
| 3ï¸âƒ£ | `num_financial_keywords` | **9.82%** | ğŸ’° Financial terms are red flags |
| 4ï¸âƒ£ | `num_urgency_keywords` | **8.06%** | â° Urgency creates pressure |
| 5ï¸âƒ£ | `has_phone` | **3.37%** | ğŸ“ Less important than expected |

### ğŸ’¡ Key Insights:

- **`is_personal_number`** dominates (63.44%)!
  - Smishing attacks primarily from personal numbers
  - Brandnames/Shortcodes are more trusted
  
- **URL presence** is 2nd most important
  - Consistent with paper findings
  
- **Phone numbers** surprisingly less important
  - Many legitimate SMS also contain phone numbers

---

## ğŸ“Š Dataset Statistics

### Train-Test Split:
- **Training**: 2,082 samples (80%)
- **Test**: 521 samples (20%)
- **Stratified**: Yes (maintains label ratio)

### Label Distribution:
```
Ham (0):      2,319 samples (89.1%)
Smishing (1):   284 samples (10.9%)
Ratio:         1:8.2 (severely imbalanced)
```

### Features Used (Top 5):
1. `has_url` - Binary (0/1)
2. `has_phone` - Binary (0/1)
3. `num_financial_keywords` - Count (0-8)
4. `num_urgency_keywords` - Count (0-4)
5. `is_personal_number` - Binary (0/1)

---

## ğŸ¨ Visualizations Created

âœ… **`model_comparison.png`** includes:

1. **Accuracy Bar Chart**
   - Horizontal bars showing all models
   - Red line marking paper benchmark (97.93%)

2. **All Metrics Comparison**
   - Grouped bar chart
   - Accuracy, Precision, Recall, F1-Score

3. **ROC Curves**
   - All 4 models overlaid
   - AUC scores in legend

4. **Confusion Matrix** (Best Model)
   - True Positives, False Positives
   - True Negatives, False Negatives

---

## ğŸš€ Next Steps to Improve

### 1. **Handle Imbalanced Data** ğŸ¯
**Priority: HIGH**

```python
# Option A: SMOTE (Synthetic Minority Over-sampling)
from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)

# Option B: Class Weights
rf = RandomForestClassifier(class_weight='balanced')
```

**Expected Impact**: +5-10% Recall, +3-5% Accuracy

---

### 2. **Hyperparameter Tuning** âš™ï¸
**Priority: MEDIUM**

```python
from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 20, 30, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

grid_search = GridSearchCV(rf, param_grid, cv=5)
```

**Expected Impact**: +1-3% Accuracy

---

### 3. **Implement Domain Checking Phase** ğŸ”
**Priority: HIGH**

```python
# Check URL legitimacy
- WHOIS lookup (domain age)
- Blacklist checking (PhishTank, Google Safe Browsing)
- SSL certificate validation
- Domain reputation score
```

**Expected Impact**: +2-5% Accuracy (closer to paper)

---

### 4. **Feature Engineering** ğŸ”§
**Priority: MEDIUM**

Add more features:
- **URL features**: TLD suspicious (.xyz, .top), IP address, shortened URLs
- **Text features**: ALL CAPS ratio, excessive punctuation (!!! ???)
- **Temporal features**: Time of day, day of week
- **Sender features**: Known scammer numbers database

**Expected Impact**: +2-4% Accuracy

---

### 5. **Ensemble Methods** ğŸ­
**Priority: LOW**

```python
# Voting Classifier
from sklearn.ensemble import VotingClassifier
ensemble = VotingClassifier([
    ('rf', RandomForestClassifier()),
    ('svm', SVC(probability=True)),
    ('lr', LogisticRegression())
], voting='soft')
```

**Expected Impact**: +1-2% Accuracy

---

## ğŸ“‚ Output Files

All files saved to `data/processed/`:

| File | Size | Description |
|------|------|-------------|
| `best_model_rf.pkl` | ~50 KB | Trained Random Forest model |
| `scaler.pkl` | ~2 KB | StandardScaler for features |
| `model_results.csv` | ~1 KB | All models' metrics table |
| `model_comparison.png` | ~100 KB | 4 visualization plots |
| `features_top5.csv` | 38 KB | Processed dataset (Top 5 features) |
| `features_full.csv` | 1 MB | All 32 features |

---

## ğŸ“ Usage Example

### Load and Use Best Model:

```python
import joblib
import pandas as pd

# Load model and scaler
model = joblib.load('data/processed/best_model_rf.pkl')
scaler = joblib.load('data/processed/scaler.pkl')

# New SMS to predict
new_sms = pd.DataFrame({
    'has_url': [1],
    'has_phone': [0],
    'num_financial_keywords': [3],
    'num_urgency_keywords': [2],
    'is_personal_number': [1]
})

# Predict (no scaling needed for Random Forest)
prediction = model.predict(new_sms)
probability = model.predict_proba(new_sms)

print(f"Prediction: {'Smishing' if prediction[0] == 1 else 'Ham'}")
print(f"Confidence: {probability[0][prediction[0]] * 100:.2f}%")
```

---

## ğŸ¯ Conclusion

### âœ… Achievements:

1. âœ”ï¸ **Successfully trained 4 ML models**
2. âœ”ï¸ **93.09% accuracy** - Very good baseline
3. âœ”ï¸ **86% precision** - High confidence predictions
4. âœ”ï¸ **0.86 AUC-ROC** - Excellent discrimination
5. âœ”ï¸ **Identified key features** - `is_personal_number` dominates
6. âœ”ï¸ **Fast training** - All models < 4 seconds

### âš ï¸ Areas for Improvement:

1. âŒ **Low recall (44%)** - Missing 56% of Smishing
2. âŒ **4.84% below paper** - Need Domain Checking Phase
3. âŒ **Imbalanced data** - SMOTE recommended
4. âŒ **Default hyperparameters** - Tuning needed

### ğŸ‰ Overall Assessment:

**Grade: B+ (Very Good)**

For a **first iteration** using only **content-based features** and **default parameters**, achieving **93.09% accuracy** is **excellent**! With the recommended improvements (SMOTE + Domain Checking), we can realistically reach **95-97% accuracy**, very close to the paper's result.

---

**ğŸš€ Next Milestone**: Implement SMOTE for class balancing and re-train models to boost recall!

---

*Generated by train_models.py - IE403 Final Project*  
*Date: December 9, 2025*

