"""
Smishing/data_loader.py
=======================
Module load dá»¯ liá»‡u Ä‘áº§u vÃ o cho toÃ n bá»™ há»‡ thá»‘ng Smishing Detection.
Xá»­ lÃ½ cÃ¡c trÆ°á»ng há»£p CSV phá»©c táº¡p cÃ³ dáº¥u nhÃ¡y kÃ©p, dáº¥u pháº©y trong content.
"""

import pandas as pd
import io
from typing import Union, List
from pathlib import Path


class DataLoader:
    """
    Class load vÃ  tiá»n xá»­ lÃ½ dá»¯ liá»‡u CSV cho há»‡ thá»‘ng Smishing Detection.
    
    Example:
        >>> loader = DataLoader()
        >>> df = loader.load('data/dataset.csv')
        
        # Hoáº·c dÃ¹ng static method
        >>> df = DataLoader.load_csv('data/dataset.csv')
    """
    
    # CÃ¡c cá»™t cá»‘ Ä‘á»‹nh á»Ÿ cuá»‘i file CSV
    DEFAULT_TAIL_COLS = ['label', 'has_url', 'has_phone_number', 'sender_type']
    
    def __init__(self, encoding: str = 'utf-8'):
        self.encoding = encoding
    
    @staticmethod
    def load_csv(file_path: Union[str, Path], 
                 fixed_tail_cols: int = 4,
                 encoding: str = 'utf-8',
                 try_standard_first: bool = True) -> pd.DataFrame:
        """
        Load file CSV, tá»± Ä‘á»™ng xá»­ lÃ½ cÃ¡c trÆ°á»ng há»£p phá»©c táº¡p.
        
        Args:
            file_path: ÄÆ°á»ng dáº«n tá»›i file CSV
            fixed_tail_cols: Sá»‘ cá»™t cá»‘ Ä‘á»‹nh á»Ÿ cuá»‘i (default: 4)
            encoding: Encoding cá»§a file
            try_standard_first: Thá»­ pd.read_csv() trÆ°á»›c
            
        Returns:
            pd.DataFrame
        """
        file_path = Path(file_path)
        
        if not file_path.exists():
            raise FileNotFoundError(f"File khÃ´ng tá»“n táº¡i: {file_path}")
        
        # Thá»­ Ä‘á»c báº±ng cÃ¡ch chuáº©n trÆ°á»›c
        if try_standard_first:
            try:
                df = pd.read_csv(file_path, encoding=encoding)
                print(f"âœ… Loaded {len(df):,} rows from {file_path.name} (standard parser)")
                return df
            except Exception as e:
                print(f"âš ï¸ Standard parser failed: {e}")
                print("ğŸ”„ Switching to complex CSV parser...")
        
        # Fallback: Parser phá»©c táº¡p
        return DataLoader._load_complex_csv(file_path, fixed_tail_cols, encoding)
    
    @staticmethod
    def _load_complex_csv(file_path: Union[str, Path],
                          fixed_tail_cols: int = 4,
                          encoding: str = 'utf-8') -> pd.DataFrame:
        """
        Parser cho CSV phá»©c táº¡p cÃ³ dáº¥u nhÃ¡y kÃ©p vÃ  dáº¥u pháº©y trong content.
        
        Chiáº¿n thuáº­t: Cáº¯t tá»« pháº£i sang trÃ¡i (rsplit) Ä‘á»ƒ tÃ¡ch content 
        khá»i cÃ¡c cá»™t cá»‘ Ä‘á»‹nh á»Ÿ cuá»‘i.
        """
        processed_lines = []
        error_lines = []
        
        with open(file_path, 'r', encoding=encoding) as f:
            # Header
            header = f.readline().strip()
            processed_lines.append(header)
            
            for line_num, line in enumerate(f, start=2):
                line = line.strip()
                if not line:
                    continue
                
                # Cáº¯t tá»« pháº£i sang trÃ¡i
                parts = line.rsplit(',', fixed_tail_cols)
                
                if len(parts) < fixed_tail_cols + 1:
                    error_lines.append((line_num, line[:80]))
                    continue
                
                messy_content = parts[0]
                clean_tail = parts[1:]
                
                # Xá»­ lÃ½ content
                if messy_content.startswith('"') and messy_content.endswith('"'):
                    messy_content = messy_content[1:-1]
                
                # Thay " báº±ng ' Ä‘á»ƒ trÃ¡nh lá»—i
                fixed_content = messy_content.replace('"', "'")
                
                # ÄÃ³ng gÃ³i láº¡i
                final_content = f'"{fixed_content}"'
                new_line = final_content + "," + ",".join(clean_tail)
                processed_lines.append(new_line)
        
        # Log lá»—i
        if error_lines:
            print(f"âš ï¸ {len(error_lines)} dÃ²ng bá»‹ bá» qua do lá»—i format")
            for ln, content in error_lines[:3]:
                print(f"   Line {ln}: {content}...")
        
        # Táº¡o DataFrame
        virtual_file = io.StringIO("\n".join(processed_lines))
        df = pd.read_csv(virtual_file)
        
        print(f"âœ… Loaded {len(df):,} rows from {Path(file_path).name} (complex parser)")
        return df
    
    @staticmethod
    def load_multiple(file_paths: List[Union[str, Path]], 
                      **kwargs) -> pd.DataFrame:
        """
        Load vÃ  gá»™p nhiá»u file CSV.
        
        Args:
            file_paths: Danh sÃ¡ch Ä‘Æ°á»ng dáº«n file
            **kwargs: CÃ¡c tham sá»‘ truyá»n cho load_csv()
            
        Returns:
            pd.DataFrame Ä‘Ã£ gá»™p
        """
        dfs = []
        for fp in file_paths:
            df = DataLoader.load_csv(fp, **kwargs)
            df['_source_file'] = Path(fp).name  # ÄÃ¡nh dáº¥u nguá»“n
            dfs.append(df)
        
        merged = pd.concat(dfs, ignore_index=True)
        print(f"ğŸ“Š Merged {len(merged):,} total rows from {len(file_paths)} files")
        return merged


# === LOAD DATASET FUNCTIONS ===

def load_dataset(file_path: Union[str, Path], **kwargs) -> pd.DataFrame:
    """Shortcut function Ä‘á»ƒ load dataset"""
    return DataLoader.load_csv(file_path, **kwargs)


def load_datasets(*file_paths, **kwargs) -> pd.DataFrame:
    """Shortcut function Ä‘á»ƒ load vÃ  merge nhiá»u datasets"""
    return DataLoader.load_multiple(list(file_paths), **kwargs)