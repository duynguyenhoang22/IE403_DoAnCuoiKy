"""
Test Suite for Layer 4: Misspell Detection
==========================================
Covers:
1. OOV (Out-Of-Vocabulary) Detection
2. Dual-Lookup Logic (Full dict vs Shadow dict)
3. Broken Telex Detection (dd, aa, ee...)
4. Gibberish Detection (No vowels, Consonant clusters)
5. Repeated Character Detection (aaa, nnn)
6. Run-on Word Detection (d√≠nh t·ª´)
7. Density Calculation
8. Integration with Layer 3 output
"""

import pytest
import sys
import pandas as pd
import ast
from pathlib import Path

# === SETUP PATH ===
ROOT_DIR = Path(__file__).resolve().parent.parent.parent.parent
sys.path.insert(0, str(ROOT_DIR))

from Smishing.misspell_detection.layer4_misspell import MisspellExtractor, MisspellResult


# ============================================================
# FIXTURES
# ============================================================

@pytest.fixture
def mock_dicts():
    """T·∫°o t·ª´ ƒëi·ªÉn gi·∫£ l·∫≠p ƒë·ªÉ test logic ƒë·ªôc l·∫≠p v·ªõi file words.txt"""
    # T·ª´ ƒëi·ªÉn c√≥ d·∫•u
    full_dict = {
        'xin', 'ch√†o', 'b·∫°n', 'th√¥ng', 'b√°o', 't√†i', 'kho·∫£n', 
        'ng√¢n', 'h√†ng', 'vui', 'l√≤ng', 'li√™n', 'h·ªá',
        'ƒë∆∞·ªùng', 'ph·ªë', 'ƒÉn', 'c∆°m'
    }
    # T·ª´ ƒëi·ªÉn kh√¥ng d·∫•u (Shadow)
    shadow_dict = {
        'xin', 'chao', 'ban', 'thong', 'bao', 'tai', 'khoan', 
        'ngan', 'hang', 'vui', 'long', 'lien', 'he',
        'duong', 'pho', 'an', 'com'
    }
    return full_dict, shadow_dict

@pytest.fixture
def extractor(mock_dicts):
    """Fixture t·∫°o MisspellExtractor v·ªõi t·ª´ ƒëi·ªÉn gi·∫£ l·∫≠p"""
    full, shadow = mock_dicts
    return MisspellExtractor(full_dict=full, shadow_dict=shadow)

# ============================================================
# TEST GROUP 1: BASIC OOV & DUAL LOOKUP
# ============================================================

class TestOOVDetection:
    """Tests c∆° b·∫£n v·ªÅ ph√°t hi·ªán t·ª´ l·∫° v√† c∆° ch·∫ø tra t·ª´ ƒëi·ªÉn k√©p"""

    def test_valid_words_full_dict(self, extractor):
        """T·ª´ c√≥ trong full_dict kh√¥ng ph·∫£i l√† OOV"""
        tokens = ['xin', 'ch√†o', 'b·∫°n']
        res = extractor.extract(tokens)
        assert res.oov_count == 0
        assert res.oov_density == 0.0

    def test_valid_words_shadow_dict(self, extractor):
        """T·ª´ kh√¥ng d·∫•u (c√≥ trong shadow_dict) kh√¥ng ph·∫£i l√† OOV"""
        tokens = ['xin', 'chao', 'ban'] # chao, ban n·∫±m trong shadow
        res = extractor.extract(tokens)
        assert res.oov_count == 0

    def test_oov_word(self, extractor):
        """T·ª´ ho√†n to√†n l·∫° l√† OOV"""
        tokens = ['xin', 'chao', 'kaka', 'xyz']
        res = extractor.extract(tokens)
        assert res.oov_count == 2
        assert 'kaka' in res.oov_tokens
        assert 'xyz' in res.oov_tokens

    def test_case_insensitive(self, extractor):
        """Ki·ªÉm tra kh√¥ng ph√¢n bi·ªát hoa th∆∞·ªùng"""
        tokens = ['XIN', 'Ch√†O', 'B·∫†N'] # N√™n ƒë∆∞·ª£c normalize v√† t√¨m th·∫•y
        res = extractor.extract(tokens)
        assert res.oov_count == 0

    def test_ignore_digits_and_short(self, extractor):
        """B·ªè qua s·ªë v√† t·ª´ qu√° ng·∫Øn (<2 chars)"""
        # '123' l√† s·ªë -> ignore
        # 'a' l√† ng·∫Øn -> ignore
        # 'xyz' l√† OOV
        tokens = ['123', 'a', 'xyz'] 
        res = extractor.extract(tokens)
        
        # Ch·ªâ c√≥ 'xyz' ƒë∆∞·ª£c check v√† t√≠nh l√† OOV
        # '123' v√† 'a' kh√¥ng ƒë∆∞·ª£c t√≠nh v√†o checked_token_count
        assert res.oov_count == 1
        assert res.oov_density == 1.0  # 1 OOV / 1 Checked


# ============================================================
# TEST GROUP 2: ADVANCED MISSPELL FEATURES
# ============================================================

class TestAdvancedFeatures:
    """Tests c√°c t√≠nh nƒÉng n√¢ng cao: Telex, Gibberish, Repeated..."""

    def test_broken_telex(self, extractor):
        """Ph√°t hi·ªán l·ªói b·ªô g√µ Telex (aa, dd, ee...)"""
        # 'dduwowng' (ƒë∆∞·ªùng), 'aam' (√¢m)
        tokens = ['dduwowng', 'aam', 'xin']
        res = extractor.extract(tokens)
        
        assert res.oov_count == 2
        assert res.broken_telex_count == 2
        assert 'dduwowng' in res.oov_tokens

    def test_gibberish(self, extractor):
        """Ph√°t hi·ªán t·ª´ v√¥ nghƒ©a (kh√¥ng nguy√™n √¢m, consonant cluster)"""
        # 'xkqz' (no vowel), 'strng' (consonant cluster)
        tokens = ['xkqz', 'strng', 'b·∫°n']
        res = extractor.extract(tokens)
        
        assert res.gibberish_count == 2
        assert res.oov_count == 2

    def test_repeated_chars(self, extractor):
        """Ph√°t hi·ªán l·∫∑p k√Ω t·ª± > 2 l·∫ßn"""
        # 'hottt', 'ngannn'
        tokens = ['hottt', 'ngannn', 'vui']
        res = extractor.extract(tokens)
        
        assert res.repeated_char_count == 2
        assert res.oov_count == 2

    def test_run_on_words(self, extractor):
        """Ph√°t hi·ªán d√≠nh t·ª´ (Run-on)"""
        # 'xinchao' (xin + chao), 'nganhang' (ngan + hang)
        # C√°c t·ª´ ƒë∆°n ph·∫£i c√≥ trong mock_dicts
        tokens = ['xinchao', 'nganhang', 'unknowntoken']
        res = extractor.extract(tokens)
        
        assert res.run_on_word_count == 2
        assert res.oov_count == 3  # V·∫´n l√† OOV nh∆∞ng ƒë∆∞·ª£c flag th√™m l√† run-on


# ============================================================
# TEST GROUP 3: METRICS & EDGE CASES
# ============================================================

class TestMetrics:
    def test_density_calculation(self, extractor):
        """T√≠nh to√°n m·∫≠t ƒë·ªô l·ªói ch√≠nh x√°c"""
        # 2 t·ª´ ƒë√∫ng (xin, chao), 2 t·ª´ sai (kaka, hoho)
        tokens = ['xin', 'chao', 'kaka', 'hoho']
        res = extractor.extract(tokens)
        
        assert res.oov_count == 2
        # Density = 2 OOV / 4 Checked = 0.5
        assert res.oov_density == 0.5

    def test_density_with_ignored_tokens(self, extractor):
        """T√≠nh m·∫≠t ƒë·ªô kh√¥ng bao g·ªìm token b·ªã b·ªè qua"""
        # 1 t·ª´ ƒë√∫ng (xin), 1 t·ª´ sai (kaka), 2 token b·ªã b·ªè qua (123, a)
        tokens = ['xin', 'kaka', '123', 'a']
        res = extractor.extract(tokens)
        
        # Checked tokens = ['xin', 'kaka'] (Total 2)
        # OOV = ['kaka'] (Total 1)
        assert res.oov_count == 1
        assert res.oov_density == 0.5

    def test_longest_oov(self, extractor):
        """T√¨m ƒë·ªô d√†i t·ª´ OOV d√†i nh·∫•t"""
        tokens = ['abc', 'abcde', 'a'] 
        res = extractor.extract(tokens)
        
        # 'a' ignored. 'abc' (3) and 'abcde' (5) are OOV.
        assert res.longest_oov_length == 5


# ============================================================
# INTEGRATION TEST & EXPORT
# ============================================================

def export_misspell_results():
    """
    Ch·∫°y Layer 4 tr√™n k·∫øt qu·∫£ c·ªßa Layer 3 v√† xu·∫•t CSV.
    Input: layer3_whitelist_results.csv
    Output: layer4_misspell_results.csv
    """
    input_file = Path("layer3_whitelist_results.csv")
    output_file = Path("layer4_misspell_results.csv")
    
    if not input_file.exists():
        print(f"‚ö†Ô∏è Input file not found: {input_file}")
        print("Skipping export test.")
        return

    print(f"\nLoading Layer 3 results from: {input_file}")
    df = pd.read_csv(input_file)
    
    # Init Extractor v·ªõi t·ª´ ƒëi·ªÉn th·∫≠t (T·ª± ƒë·ªông load words.txt)
    # L∆∞u √Ω: Class MisspellExtractor m·∫∑c ƒë·ªãnh s·∫Ω t·ª± t√¨m file words.txt n·∫øu kh√¥ng truy·ªÅn tham s·ªë
    # ho·∫∑c b·∫°n c√≥ th·ªÉ tr·ªè ƒë∆∞·ªùng d·∫´n c·ª• th·ªÉ n·∫øu c·∫ßn.
    try:
        extractor = MisspellExtractor() 
        print(f"Dictionary loaded via Extractor logic.")
    except Exception as e:
        print(f"Error loading dictionary: {e}")
        return

    results = []
    
    print("Running Misspell Extraction...")
    
    for _, row in df.iterrows():
        # Convert string representation of list back to list
        # Layer 3 output column: 'tokens_to_check'
        tokens_str = row.get('tokens_to_check', '[]')
        try:
            tokens = ast.literal_eval(tokens_str) if isinstance(tokens_str, str) else []
        except:
            tokens = []
            
        res = extractor.extract(tokens)
        
        results.append({
            # Copy basic info
            'index': row.get('index'),
            'label': row.get('label'),
            'original_content': row.get('original_content'),
            
            # Layer 3 info
            'tokens_to_check': tokens,
            
            # Layer 4 Results
            'oov_count': res.oov_count,
            'oov_density': round(res.oov_density, 4),
            'broken_telex_count': res.broken_telex_count,
            'gibberish_count': res.gibberish_count,
            'repeated_char_count': res.repeated_char_count,
            'run_on_word_count': res.run_on_word_count,
            'longest_oov_len': res.longest_oov_length,
            'oov_tokens': res.oov_tokens
        })
    
    result_df = pd.DataFrame(results)
    result_df.to_csv(output_file, index=False, encoding="utf-8-sig")
    
    print(f"\n‚úÖ Results saved to: {output_file}")
    print(f"   Total rows processed: {len(result_df):,}")
    
    # Th·ªëng k√™ s∆° b·ªô
    print("\nüìä SUMMARY STATISTICS (Layer 4):")
    print("-" * 40)
    print(f"   Avg OOV Density:        {result_df['oov_density'].mean():.4f}")
    print(f"   Avg Broken Telex:       {result_df['broken_telex_count'].mean():.2f}")
    print(f"   Avg Gibberish:          {result_df['gibberish_count'].mean():.2f}")
    print(f"   Avg Repeated Chars:     {result_df['repeated_char_count'].mean():.2f}")
    
    return result_df


# ============================================================
# MAIN
# ============================================================

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Layer 4 Misspell Tests")
    parser.add_argument("--export", action="store_true", help="Export results to CSV")
    parser.add_argument("--test", action="store_true", help="Run pytest tests")
    
    args = parser.parse_args()
    
    if args.export:
        export_misspell_results()
    elif args.test:
        pytest.main([__file__, "-v", "--tb=short"])
    else:
        # Default behavior: run export if no args
        print("Usage:")
        print("  python test_layer4.py --test    (Run Unit Tests)")
        print("  python test_layer4.py --export  (Run on Dataset & Save CSV)")
        print("\nRunning export by default...")
        export_misspell_results()