import joblib
import logging
import warnings
import unicodedata
import re  # C·∫ßn import th√™m re ƒë·ªÉ x·ª≠ l√Ω Regex boundary

warnings.filterwarnings("ignore")
logging.getLogger('xgboost').setLevel(logging.WARNING)

try:
    from features import SmishingFeatureExtractor
    from domain_check import DomainVerifier
except ImportError as e:
    print(f"‚ùå L·ªñI IMPORT SYSTEM: {e}")
    exit()

class SmishingDetectionSystem:
    def __init__(self, model_path='smsishing_xgb.pkl', encoder_path='sender_encoder.pkl', threshold=0.46, model_name='Default'):
        self.threshold = threshold
        self.model_name = model_name
        print(f"üîÑ Starting System (Threshold={self.threshold})...")
        try:
            self.model = joblib.load(model_path)
            self.le = joblib.load(encoder_path)
            self.extractor = SmishingFeatureExtractor()
            self.verifier = DomainVerifier()
            print("‚úÖ SYSTEM READY!")
        except Exception as e:
            print(f"FAIL: {e}")
            exit()

    def _simple_normalize(self, text: str) -> str:
        """Chu·∫©n h√≥a nh·∫π ƒë·ªÉ so kh·ªõp t·ª´ kh√≥a."""
        text = unicodedata.normalize("NFKD", text)
        text = "".join(ch for ch in text if not unicodedata.combining(ch))
        return text.lower()

    def predict(self, text, sender_type='unknown'):
        # ---------------------------------------------------------
        # B∆Ø·ªöC 1: AI SCORING (BASELINE)
        # ---------------------------------------------------------
        text_features = self.extractor.extract_features(text)
        try:
            sender_code = self.le.transform([sender_type])[0]
        except:
            sender_code = 0 
            
        full_vector = [sender_code] + text_features
        ai_prob = float(self.model.predict_proba([full_vector])[:, 1][0])

        # ---------------------------------------------------------
        # B∆Ø·ªöC 2: DOMAIN VERIFICATION
        # ---------------------------------------------------------
        domain_status, domain_reason, risk_score = self.verifier.verify(text)

        # ---------------------------------------------------------
        # B∆Ø·ªöC 3: CONTEXT ANALYSIS (PH√ÇN T√çCH NG·ªÆ C·∫¢NH)
        # ---------------------------------------------------------
        norm_text = self._simple_normalize(text)

        # 3.1. Conversation Guard (B·ªô l·ªçc h·ªôi tho·∫°i)
        # D√πng Regex \b ƒë·ªÉ b·∫Øt ch√≠nh x√°c t·ª´ ƒë∆°n, tr√°nh b·∫Øt nh·∫ßm (VD: 'bo' trong 'bo cong an')
        conversational_regex = [
            r'\btao\b', r'\bmay\b', r'\bba\b', r'\bme\b', r'\bbo\b', 
            r'\banh\b', r'\bem\b', r'\bchi\b', r'\bminh\b', r'\bvo\b', r'\bchong\b'
        ]
        
        # C√°c c·ª•m t·ª´ d√†i th√¨ d√πng string matching b√¨nh th∆∞·ªùng cho nhanh
        conversational_phrases = [
            'sinh nhat', 'an com', 'di choi', 'di nhau', 'cafe', 
            'hop lop', 'lam viec', 'gui xe', 've chua', 
            'nha mang', 'qc', 'quang cao' # Ch·∫•p nh·∫≠n tin qu·∫£ng c√°o nh√† m·∫°ng l√† an to√†n
        ]

        is_conversational = False
        # Check Regex tr∆∞·ªõc
        for pattern in conversational_regex:
            if re.search(pattern, norm_text):
                is_conversational = True
                break
        
        # N·∫øu ch∆∞a th·∫•y th√¨ check ti·∫øp phrases
        if not is_conversational:
            is_conversational = any(kw in norm_text for kw in conversational_phrases)

        # 3.2. Danger Guard (B·ªô l·ªçc r·ªßi ro)
        # C√°c t·ª´ kh√≥a n√†y s·∫Ω V√î HI·ªÜU H√ìA t√≠nh nƒÉng h·ªôi tho·∫°i ·ªü tr√™n
        danger_kw = [
            # Nh√≥m t√†i ch√≠nh (D·ªÖ b·ªã gi·∫£ danh ng∆∞·ªùi th√¢n)
            'vay', 'no xau', 'lai suat', 'giai ngan', 
            'chuyen khoan', 'stk', 'ngan hang', 'bank', 'so du',
            
            # Nh√≥m vi·ªác l√†m/L·ª´a ƒë·∫£o
            'viec nhe', 'ctv', 'hoa hong', 'chot don', 'tuyen dung',
            'trung thuong', 'qua tang', 
            
            # Nh√≥m gi·∫£ danh c∆° quan (Quan tr·ªçng)
            'cong an', 'toa an', 'lenh bat', 'dieu tra', 'trieu tap'
        ]
        has_danger = any(kw in norm_text for kw in danger_kw)

        # ---------------------------------------------------------
        # B∆Ø·ªöC 4: HYBRID DECISION (QUY·∫æT ƒê·ªäNH CU·ªêI C√ôNG)
        # ---------------------------------------------------------
        
        final_score = ai_prob
        final_reason = ""
        is_smishing = False
        decision_phase = "AI Model"

        # --- LOGIC 1: DOMAIN ƒê·ªòC H·∫†I (RISK = 1.0) ---
        if risk_score >= 0.8:
            final_score = 1.0
            is_smishing = True
            decision_phase = "Domain Risk"
            final_reason = f"C·∫¢NH B√ÅO CAO: Ph√°t hi·ªán li√™n k·∫øt ƒë·ªôc h·∫°i ho·∫∑c b·ªã l√†m nhi·ªÖu ({domain_reason})."

        # --- LOGIC 2: WHITELIST (RISK = -1.0) ---
        elif risk_score == -1.0:
            ugc_keywords = ['google', 'drive', 'docs', 'sheet', 'form', 'dropbox', 'bit.ly', 'tinyurl', 'zalopay']
            is_ugc_platform = any(kw in domain_reason.lower() for kw in ugc_keywords)

            if is_ugc_platform:
                # Hybrid check cho Google Form/Drive
                if ai_prob > 0.65:
                    final_score = ai_prob
                    is_smishing = True
                    decision_phase = "Hybrid Warning"
                    final_reason = f"C·∫£nh b√°o: T√™n mi·ªÅn s·∫°ch ({domain_reason}) nh∆∞ng n·ªôi dung c√≥ d·∫•u hi·ªáu l·ª´a ƒë·∫£o."
                else:
                    final_score = 0.2
                    is_smishing = False
                    decision_phase = "Hybrid Safe"
                    final_reason = "An to√†n: T√™n mi·ªÅn d·ªãch v·ª• l∆∞u tr·ªØ/r√∫t g·ªçn uy t√≠n."
            else:
                final_score = 0.0
                is_smishing = False
                decision_phase = "Authority Whitelist"
                final_reason = f"An to√†n: T√™n mi·ªÅn ch√≠nh ch·ªß ƒë√£ ƒë∆∞·ª£c x√°c th·ª±c ({domain_reason})."

        # --- LOGIC 3: AI + SAFETY NET ---
        else:
            if ai_prob >= self.threshold:
                # AI nghi ng·ªù -> Ki·ªÉm tra Safety Net
                if is_conversational and not has_danger:
                    # AI cao + H·ªôi tho·∫°i + KH√îNG nguy hi·ªÉm -> Safe
                    final_score = 0.25
                    is_smishing = False
                    decision_phase = "Conversation Guard"
                    final_reason = "C·∫£nh b√°o m·ª©c th·∫•p: AI nghi ng·ªù nh∆∞ng vƒÉn phong mang t√≠nh h·ªôi tho·∫°i c√° nh√¢n."
                else:
                    # AI cao + (Kh√¥ng ph·∫£i h·ªôi tho·∫°i HO·∫∂C C√≥ nguy hi·ªÉm) -> Scam
                    is_smishing = True
                    decision_phase = "AI Detection"
                    final_reason = "C·∫£nh b√°o: AI ph√°t hi·ªán c·∫•u tr√∫c vƒÉn b·∫£n th∆∞·ªùng th·∫•y trong tin nh·∫Øn r√°c/l·ª´a ƒë·∫£o."
            else:
                # AI th·∫•y an to√†n -> Ki·ªÉm tra s√≥t l·ªçt
                if has_danger and sender_type != 'brandname':
                    # AI th·∫•p + C√≥ t·ª´ kh√≥a nguy hi·ªÉm -> Scam
                    final_score = 0.6
                    is_smishing = True
                    decision_phase = "Keyword Trigger"
                    final_reason = "C·∫£nh b√°o: N·ªôi dung ch·ª©a c√°c t·ª´ kh√≥a r·ªßi ro cao (T√†i ch√≠nh/Gi·∫£ danh) c·∫ßn x√°c minh."
                else:
                    is_smishing = False
                    final_reason = "An to√†n: Kh√¥ng t√¨m th·∫•y y·∫øu t·ªë r·ªßi ro trong n·ªôi dung."

        return {
            "text": text,
            "sender": sender_type,
            "is_smishing": is_smishing,
            "confidence": float(final_score),
            "raw_ai_score": float(ai_prob),   # ƒêi·ªÉm g·ªëc AI ƒë·ªÉ debug
            "domain_risk": risk_score,        # ƒêi·ªÉm g·ªëc Domain ƒë·ªÉ debug
            "reason": final_reason,
            "phase": decision_phase
        }